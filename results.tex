\chapter{Results}
\label{cha:results}

\section{Final Distribution}
\label{sec:final-dist}

Having accounted for the systematic uncertainties, one can examine the final distribution(s). This encompasses the mass of the gaugino and smuon, where the former is part of the latter. In case of the smuon, the selected two jets and the two muons enter the invariant mass calculation. Removing the leading muon from this composition yields the gaugino case. All event selection requirements are applied and in relation to the control region BVC, only the inverted missing transverse energy requirement is reversed again $E_{\text{T}}^{\text{miss}} < 50$. Figure~\ref{fig:final-dist} shows both distributions including the data-driven background estimate.

\begin{figure}[htb!]
  \centering
  \begin{subfigure}[b]{0.495\textwidth}
    \centering
    \includegraphics[width=\textwidth]{plots/m_gaugino.pdf}
    \caption{\label{fig:m_gaugino}}
  \end{subfigure}
  \begin{subfigure}[b]{0.495\textwidth}
    \centering
    \includegraphics[width=\textwidth]{plots/m_smuon.pdf}
    \caption{\label{fig:m_smuon}}
  \end{subfigure}
  \caption{Mass of the gaugino (\ref{fig:m_gaugino}) and smuon (\ref{fig:m_smuon}). Both are calculated from the invariant masses of the selected two jets and two muons in the smuon case, as well as two jets and the sub leading muon for the gaugino. The distributions include the data-driven background estimate.}
  \label{fig:final-dist}
\end{figure}

\noindent Table~\ref{tab:nev-msmuon} resolves each group of processes into it's individual background components. The importance of the data-driven background estimate is shown by its large contribution. Combined with the $WZ \rightarrow 3l \nu$ process, it adds up to more than $80\,\pct$ of the entire background prediction.

\begin{table}[!htb]
  \centering
  \begin{tabular}{|l|c|c|c|}
    \hline
    \multirow{2}{*}{Backgrounds}    & \multirow{2}{*}{$N_{\text{Events}}$} & \multicolumn{2}{|c|}{Uncertainties} \\ \cline{3-4}
                                    &                                      & stat.   & sys.                      \\ \hline \hline
    Fake estimate                   & 33.5                                 & 2.42    & 16                        \\ \hline
    $W\gamma \rightarrow l\nu 2\mu$ & 1.35                                 & 0.453   & 0.687                     \\
    $WZ \rightarrow 3l \nu$         & 17.1                                 & 0.46    & 1.87                      \\
    $WZ \rightarrow 2q l \nu$       & 0.0259                               & 0.0259  & 0.00284                   \\
    $ZZ \rightarrow 2l 2q$          & 0.0435                               & 0.0298  & 0.00441                   \\
    $ZZ \rightarrow 4l$             & 2.55                                 & 0.0464  & 0.27                      \\ \hline
    $t\bar{t} + W$                  & 1.0                                  & 0.157   & 0.303                     \\
    $t\bar{t} + WW$                 & 0.0163                               & 0.0019  & 00083                     \\
    $t\bar{t} + Z$                  & 0.258                                & 0.0704  & 0.0383                    \\ \hline
    $WWW$                           & 0.842                                & 0.0807  & 0.0852                    \\
    $WWZ$                           & 0.186                                & 0.0336  & 0.02                      \\
    $WZZ$                           & 0.186                                & 0.013   & 0.00932                   \\
    $ZZZ$                           & 0.0554                               & 0.00178 & 0.000531                  \\ \hline
    $W^- W^-$                       & 1.38                                 & 0.167   & 0.7                       \\
    $W^+ W^+$                       & 3.97                                 & 0.476   & 2.02                      \\
    $WW$ Double-parton              & 0.242                                & 0.067   & 0.123                     \\ \hline
    $\sum$                          & 62.5                                 & 2.57    & 22.1                      \\ \hline
    Data                            & 63                                   & -       & -                         \\ \hline
  \end{tabular}
  \caption{Detailed number of events for each background in the distributions at the final stage of the analysis.}
  \label{tab:nev-msmuon}
\end{table}

\noindent Taking the signal point with $m_0 = 1000\,\text{GeV}$ and $m_{1/2} = 200\,\text{GeV}$ in figure~\ref{fig:final-dist} as an example, one can see that while the distributions coincide in the gaugino mass distribution, they do not in the smuon one. To improve the results, a multi-bin approach is being used. For that purpose, the two dimensional gaugino-smuon mass distribution is divided into six regions, which is shown in figure~\ref{fig:m_smu_chi}.

\begin{figure}[!htb]
  \centering
  \includegraphics[width=0.7\textwidth]{plots/m_smu_chi.pdf}
  \caption{Two-dimensional smuon and gaugino mass distribution. All backgrounds are summed up and are shown as coloured bins, while the data points are shown individually. The six regions are regarded as separate bins to improve the results of this analysis.}
  \label{fig:m_smu_chi}
\end{figure}

\noindent Most entries are centered around one diagonal line. In comparison, the aforementioned signal point has the majority of its entries at smuon masses above $1200\,\text{GeV}$. The contents of each of the six regions, are summarized in table~\ref{tab:m_smu_chi_summary}.

\begin{table}[!htbp]
  \centering
  \begin{tabular}{|l|r|r|r|}
    \hline
    Process group & SR 1              & SR 2              & SR 3              \\ \hline
    Fakes         & 16.0 $\pm$ 1.63   & 10.7 $\pm$ 1.3    & 5.00 $\pm$ 0.98   \\ 
    $tt+V$        & 0.47 $\pm$ 0.10   & 0.49 $\pm$ 0.11   & 0.187 $\pm$ 0.068 \\ 
    $VV$          & 8.46 $\pm$ 0.40   & 7.10 $\pm$ 0.40   & 4.01 $\pm$ 0.29   \\
    $VVV$         & 0.374 $\pm$ 0.051 & 0.392 $\pm$ 0.052 & 0.209 $\pm$ 0.040 \\ 
    Rare          & 1.04 $\pm$ 0.21   & 1.33 $\pm$ 0.24   & 1.65 $\pm$ 0.28   \\ \hline
    $\sum$        & 26.4 $\pm$ 9.6    & 20.0 $\pm$ 7.1      & 11.1 $\pm$ 4.0    \\ \hline
    Data          & 19                & 25                & 13                \\ \hline \hline
    Process group & SR 4                & SR 5              & SR 6              \\ \hline
    Fakes         & 0.23 $\pm$ 0.16     & 1.15 $\pm$ 0.69   & 0.33 $\pm$ 0.19   \\
    $tt+V$        & $<0.001 \pm <0.001$ & 0.032$\pm$ 0.027  & 0.094 $\pm$ 0.054 \\
    $VV$          & 0.106 $\pm$ 0.032   & 1.07 $\pm$ 0.11   & 0.277 $\pm$ 0.054 \\
    $VVV$         & 0.0062 $\pm$ 0.0047 & 0.090 $\pm$ 0.026 & 0.028 $\pm$ 0.014 \\
    Rare          & 0.102 $\pm$ 0.072   & 0.65 $\pm$ 0.17   & 0.80 $\pm$ 0.21   \\ \hline
    $\sum$        & 0.45 $\pm$ 0.25     & 3.0 $\pm$ 1.3     & 1.5 $\pm$ 0.7     \\ \hline
    Data          & 2                   & 1                 & 3                 \\ \hline
  \end{tabular}
  \caption{Summary of the six regions displayed in figure~\ref{fig:m_smu_chi}. They are numbered starting on the left and progressing upwards from the lowest bin.}
  \label{tab:m_smu_chi_summary}
\end{table}


The statistical uncertainties for the Monte Carlo predictions stem from the generated number of events, which limit the accuracy of the prediction. While the fake estimate has been determined from data, the method itself inherits said statistical uncertainties as background samples are subtracted to determine the tight-to-loose ratio. Respectively adding the uncertainties for every bin of the single- and double-fake estimates in quadrature and propagating them according to equation~\eqref{eq:fakes} yields the statistical uncertainty for this case. All systematic uncertainties are taken from the summary table (Tab.~\ref{tab:sys-uncertainties}). Individual cross section uncertainties are included in accordance to the table's description as well. Overall one can observe an excellent agreement of measurement and simulation. All variations are well within the given uncertainties.


\section{Calculation of Limits}
\label{sec:calc-of-limits}

As any excess of data is too slight to be considered a discovery, one can translate the result into limits onto two quantities. The number of events itself and RPV SUSY model parameters. To calculate these, the method commonly used amongst the CMS experiment will be utilized. Details are given in the upcoming section.


\subsection{CLs Method}
\label{sec:cls-method}

To compliment Bayesian and common frequentist methods, the $CL_s$ method~\cite{cls,cls2} has been developed. It is considered a modified frequentist analysis. Compared to the former two, its results are better in cases with low statistics and are less background dependent. The general idea is to compare two hypotheses to a measurement by determining a \textit{confidence level} (\textbf{CL}) for each of them. Confidence levels are defined as the probability of the respective hypothesis describing the measured data.

In regards to high energy particle physics, there are usually two cases to be covered. The null hypotheses being the Standard Model background expectation by itself, while the second hypotheses includes the signal as well. The corresponding likelihoods $\mathcal{L} (x)$ for both cases are the basis of this method. Here, $x$ denotes the background-only scenario for $x = b$ and the background plus signal one for $x = s + b$. The distributions are a function of the cross section corresponding to the relevant processes and therefore effectively also of the number of selected events $n$.

A test statistic $Q$ is used to determine which hypothesis is the better description. It is called the \textit{likelihood-ratio}.

\begin{equation}
  \label{eq:testq}
  Q = \frac{\mathcal{L} (s + b; n)}{\mathcal{L} (b; n)}
\end{equation}

For a result of an experiment, the observed number of events yields a set likelihood-ratio $Q_{\text{obs}}$. The confidence level for either hypothesis to be an accurate description for $Q_{\text{obs}}$, is given as

\begin{equation}
  \label{eq:cl-prob}
  CL_x = P (Q \leq Q_{obs}).
\end{equation}

\noindent Here, $P$ denotes the probability for a test statistic $Q$ being less or equal to the observed statistic $Q_{\text{obs}}$. It is determined through integration.

\begin{equation}
  \label{eq:clx}
  CL_x = \int^{Q_{\text{obs}}}_{-\infty} \frac{d f_x(Q)}{d Q} \text{d} Q
\end{equation}

\noindent The probability distribution functions are denoted by $f_x(Q)$ and are usually determined through pseudo-experiments. For a very well understood background hypothesis, a confidence level in the null hypothesis of $CL_b (Q_{\text{obs}}) \approx 1$ is necessary to claim a discovery. The specific thresholds that $1 - CL_b (Q_{\text{obs}})$ has to fall below, are derived from the Gaussian distribution. This means $2.7 \cdot 10^{-3}$ corresponds to $3\,\sigma$, which is considered ``evidence'', and $5.7 \cdot 10^{-5}$ corresponding to $5\,\sigma$, a discovery.

Excluding the signal (plus background) hypothesis uses the eponymous $CL_s$ quantity instead of $CL_{s+b}$. It is defined as a ratio:

\begin{equation}
  \label{eq:cls}
  CL_s = \frac{CL_{s+b}}{CL_b}.
\end{equation}

\noindent While $CL_{s+b}$ may lead to unphysical results in certain cases, $CL_s$ does not. A prime example is a signal hypothesis that is dominated by its background. Slight fluctuations towards lower values of the latter would lead to a very low $CL_{s+b}$, yielding a strong exclusion limit. As $CL_s$ is not a confidence limit, but a ratio of those, fluctuations like these cancel themselves out.

A signal can be excluded to a confidence level $CL$, when the following relation is fulfilled.

\begin{equation}
  \label{eq:cl-excl}
  1 - CL_s \leq CL
\end{equation}

\section{Modifications}
\label{sec:mods}

Following the recommendations by the CMS and ATLAS collaborations~\cite{clsmod}, a modified test statistic is employed for the $CL_s$ method. To scale the signal strength a parameter $\mu$ is introduced to the formula. It is used to in- or decrease the cross section of the signal prediction while the branching ratios remain constant. Additionally, both the signal and background simulation are subject to a number of uncertainties. To account for those in the limit calculation, a nuisance parameter $\theta$ is introduced.

\begin{equation}
  \label{eq:q-mod}
  Q = - 2 \ln{ \frac{\mathcal{L} (\mu s + b; n, \hat{\theta)}_\mu }{\mathcal{L} (\hat{\mu} \cdot s + b; n, \hat{\theta} )} } \quad \text{ with } \quad 0 \leq \hat{\mu} \leq \mu
\end{equation}

\noindent Here, the pair of parameters $\hat{\mu}$ and $\hat{\theta}$ are determined at the global maximum of the likelihood. $\hat{\theta}_\mu$ on the other hand denotes the conditional maximum likelihood estimator of $\theta$, which also depends on the choice of $\mu$.

% Using the logarithm with a factor of $-2$ allows the test statistic to converge against $\Delta \chi^2$ for a large number of selected events.

To improve the limits, the signal region is subdivided into multiple individual regions. When combining the results for the individual bins, the respective likelihoods have to be multiplied and the overall value is given by

\begin{equation}
  \label{eq:likelihood-product}
  \mathcal{L} = \prod_i \mathcal{L}_i.
\end{equation}

\noindent This enhances the sensitivity, as the influence of large deviations in a certain region is increased.

\section{Limit Graphs}
\label{sec:limit-graphs}

The actual calculation of limits is performed by the \textsc{HiggsCombine} tool~\cite{clsmod,higgscombine}. It employs the \textsc{RooStats} package~\cite{roostats} which is part of the statistical analysis framework \textsc{ROOT}. In line with all CMS publications, the exclusion ranges are calculated to a $95\,\pct$ confidence level as a lower limit ($CL_s \leq 0.05$). The necessary scaling of the signal strength to reach this CL can be achieved through varying the previously introduced modifier $\mu$.

While the result of the calculation is a limit on the signal cross section $\sigma$, it can be translated into a limit onto the model parameter $\lambda^\prime_{211}$. As the former scales quadratically with the latter, the following formula has to be used.

\begin{equation}
  \label{eq:xs-lambda-scale}
  \sigma \propto \lambda^\prime_{211} \Rightarrow \lambda^\prime_{211} (95\,\pct\: CL) = \lambda^\prime_{211} \cdot \sqrt{ \frac{\sigma (95\,\pct\: CL)}{\sigma} } 
\end{equation}




\section{Discussion and Thoughts}
\label{sec:discussion}



\section{Candidate Events}
\label{sec:candidate-events}


\section{Conclusion and Outlook}
\label{sec:conclusion}




%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "document"
%%% End: 
